Le Mixologue AugmentÃ© ğŸ¹
Un gÃ©nÃ©rateur de cocktails personnalisÃ©s utilisant l'intelligence artificielle avec Flask et Ollama.

Description
Ce projet permet de crÃ©er des cocktails uniques en dÃ©crivant simplement ce que vous souhaitez. L'IA gÃ©nÃ¨re une recette complÃ¨te avec les ingrÃ©dients, l'histoire du cocktail, l'ambiance musicale et une description pour l'image.

Technologies utilisÃ©es
Flask : Framework web Python
Jinja2 : Moteur de templates
SQLite : Base de donnÃ©es
Ollama : IA locale pour la gÃ©nÃ©ration de contenu
Docker : Containerisation
Bootstrap : Interface utilisateur
Architecture
Le projet utilise deux conteneurs Docker :

flask-app : Application web Flask
ollama : Serveur IA Ollama avec le modÃ¨le llama3.2
Installation et lancement
PrÃ©requis
Docker
Docker Compose

Ã‰tapes

1 ## Cloner le projet
git clone <votre-repo>
cd testNico
2 ## Lancer l'application
docker-compose up --build
3 ## AccÃ©der Ã  l'application
Interface web : http://localhost:5000
API : http://localhost:5000/api/cocktails

## Utilisation
CrÃ©er un cocktail : DÃ©crivez votre cocktail idÃ©al sur la page d'accueil
GÃ©nÃ©ration automatique : L'IA crÃ©e une recette unique
Consultation : Retrouvez tous vos cocktails dans "Mes Cocktails"
Suppression : Supprimez les cocktails que vous ne souhaitez plus garder
## Structure du projet
 testNico/
â”œâ”€â”€ view/
â”‚   â”œâ”€â”€ main.py          # Routes principales
â”‚   â”œâ”€â”€ cocktails.py     # Gestion des cocktails
â”‚   â””â”€â”€ responses.py     # GÃ©nÃ©ration IA
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html        # Template de base
â”‚   â”œâ”€â”€ home.html        # Page d'accueil
â”‚   â””â”€â”€ cocktails.html   # Liste des cocktails
â”œâ”€â”€ models.py            # ModÃ¨les de base de donnÃ©es
â”œâ”€â”€ app.py               # Application principale
â”œâ”€â”€ docker-compose.yml   # Configuration des conteneurs
â””â”€â”€ requirements.txt     # DÃ©pendances Python

## API
GET /api/cocktails : RÃ©cupÃ©rer tous les cocktails
POST /api/cocktails : CrÃ©er un nouveau cocktail
DELETE /api/cocktails/<id> : Supprimer un cocktail
GET /api/responses/test : Tester la connexion Ollama

## Configuration
Les variables d'environnement sont configurÃ©es dans docker-compose.yml :

SQLALCHEMY_DATABASE_URI : Chemin de la base de donnÃ©es
OLLAMA_URL : URL du serveur Ollama
SECRET_KEY : ClÃ© secrÃ¨te Flask

## Notes techniques
La base de donnÃ©es SQLite est crÃ©Ã©e automatiquement au premier lancement
Le modÃ¨le Ollama llama3.2 est tÃ©lÃ©chargÃ© automatiquement
L'application fonctionne sans GPU (mode CPU)

## DÃ©pannage
Erreur 404 sur les styles : Normal, Bootstrap est chargÃ© via CDN
GÃ©nÃ©ration lente : Premier appel plus long (tÃ©lÃ©chargement du modÃ¨le)
ProblÃ¨me de connexion Ollama : VÃ©rifier avec /api/responses/test

## DÃ©veloppement
Pour dÃ©velopper en local sans Docker :

pip install -r requirements.txt
export SQLALCHEMY_DATABASE_URI=sqlite:///bar_cocktails.db
python app.py


### Projet rÃ©alisÃ© dans le cadre d'un apprentissage de Flask et Docker